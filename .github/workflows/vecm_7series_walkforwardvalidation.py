# -*- coding: utf-8 -*-
"""VECM_7series_WalkforwardValidation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VzFsw54cesII5s2aCbZLOCwh8Fog2czr

author: @ Sarit Maitra

Fitting VECM with half of data to validate; 

-> Step 5: Estimating the VECM model by maximum likelihood method, test validations by visual diagnostic or correlogram, and checking that residuals from the model are white noise.
"""

print('Necessary libraries & dependencies')
!pip install pyforest
from pyforest import *
import datetime, pickle, copy, warnings, math
from pandas import DataFrame, merge, concat
plt.style.use('dark_background')
from google.colab import files
!pip install arch
from arch.unitroot import DFGLS
pd.set_option('display.max_rows', 500)
pd.set_option('display.max_columns', 500)
pd.set_option('display.width', 150)
from sklearn.metrics import mean_absolute_error, mean_squared_error
from math import sqrt
from numpy import sqrt
from statsmodels.tsa.stattools import grangercausalitytests, adfuller
from statsmodels.stats.stattools import durbin_watson
from statsmodels.tsa.vector_ar import vecm
import statsmodels.stats.api as sms
from statsmodels.compat import lzip

uploaded = files.upload()
print('view data...')
original = pd.read_csv("series_7_1.csv")
original = original.set_index('timestamp')
original = original.sort_index(ascending=True)

#original_log = np.log(original)
#original_log

original

max_lag = 6
test = 'ssr_chi2test'
def causation_matrix(data, variables, test='ssr_chi2test', verbose=False):    
  X = DataFrame(np.zeros((len(variables), len(variables))), columns=variables, index=variables)
  for c in X.columns:
    for r in X.index:
      test_result = grangercausalitytests(data[[r, c]], maxlag = max_lag, verbose = False)
      p_values = [round(test_result[i+1][0][test][1],4) for i in range(max_lag)]
      if verbose: print(f'Y = {r}, X = {c}, P Values = {p_values}')
      min_p_value = np.min(p_values)
      X.loc[r, c] = min_p_value
    X.columns = [var + '-x axis' for var in variables]
    X.index = [var + '-y axis' for var in variables]
    return X
causation_matrix(original, variables = original.columns)

"""# 1 Vector error correction model:

VECM allows to model jointly short-term dynamics (variables in first difference) and long-term dynamics (variables at level).

We have determined the lag length earlier, trend specification and the number of cointegrating relationships, we can fit the VECM model.
"""

# VECM
model = vecm.VECM(original[:15000].values, k_ar_diff = 6, coint_rank = 5, deterministic='co')

"""
k_ar_diff = lag length
set the deterministic argument to "co", meaning that there
is a constant inside the cointegrating relationship
"""
res = model.fit()
print(res.summary())

"""## 1.2 Residuals diagonistics:"""

print(res.test_normality())

"""### 1.2.1 Durbin Watson:"""

out = durbin_watson(res.resid)
for col, val in zip(original.columns, out):
    print((col), ':', round(val, 2))

residuals = res.resid

name = ['Jarque-Bera', 'Chi^2 two-tail prob.', 'Skew', 'Kurtosis']
test = sms.jarque_bera(residuals)
print(lzip(name, test)); print()
print('Correlation matrix:')
residuals = DataFrame(residuals, columns = original.columns)
print(residuals.corr()); print() # correlation matrix
print('Summary statistic:')
print(residuals.describe().transpose()) # statistic

plt.style.use('ggplot')
# Histogram plot of the forecast residual errors
plt.figure(figsize=(15,10))
residuals.hist()
plt.tight_layout()

from statsmodels.graphics.gofplots import qqplot
residuals = np.array(residuals)
qqplot(residuals, line='r')
plt.show()

#from pandas.plotting import lag_plot
#lag_plot(original)

residuals = DataFrame(residuals, columns = original.columns)
def adfuller_test(series, signif=0.05, name='', verbose=False):
    """Perform ADFuller to test for Stationarity of given series and print report"""
    r = adfuller(series, autolag='AIC')
    output = {'test_statistic':round(r[0], 4), 'pvalue':round(r[1], 4), 'n_lags':round(r[2], 4), 'n_obs':r[3]}
    p_value = output['pvalue'] 
    def adjust(val, length= 6): return str(val).ljust(length)

    # Print Summary
    print(f'    Augmented Dickey-Fuller Test on "{name}"', "\n   ", '-'*47)
    print(f' Null Hypothesis: Data has unit root. Non-Stationary.')
    print(f' Significance Level    = {signif}')
    print(f' Test Statistic        = {output["test_statistic"]}')
    print(f' No. Lags Chosen       = {output["n_lags"]}')

    for key,val in r[4].items():
        print(f' Critical value {adjust(key)} = {round(val, 3)}')

    if p_value <= signif:
        print(f" => P-Value = {p_value}. Rejecting Null Hypothesis.")
        print(f" => Series is Stationary.")
    else:
        print(f" => P-Value = {p_value}. Weak evidence to reject the Null Hypothesis.")
        print(f" => Series is Non-Stationary.")
        
# ADF Test on each column
for name, column in residuals.iteritems():
    adfuller_test(column, name=column.name)
    print()

"""## 1.3 Forecast:"""

n_obs = 2
pd.options.display.float_format = "{:.2f}".format
fcast, lower, upper = res.predict(n_obs, 0.01)
print("lower bounds of confidence intervals:")
print(lower.round(2))
print("\npoint forecasts:")
print(fcast.round(2))
print("\nupper bounds of confidence intervals:")
print(upper.round(2)); print()

fcast = DataFrame(fcast, columns = original.columns)
fcast.index = original[15000:15002].index
print(fcast); print()
print(original[15000:15002])

# reversing forecast at original level
#fcast_org = np.exp(fcast)
#fcast_org.index = original[15000:15002].index
#fcast_org

"""## 1.4 Back-testing:"""

train = original[:15000]; test = original[15000:15015]

# VECM
model = vecm.VECM(train.values, k_ar_diff = 6, coint_rank = 5, deterministic='co')
model_fit = model.fit()
print('Lag: %s' % model_fit.k_ar)
# make predictions
predictions = model_fit.predict(len(test))
predictions = DataFrame(predictions, columns = original.columns)
for i in range(len(predictions)):
  print('predicted -> %f, expected -> %f' % (predictions.eurusd[i], test.eurusd[i]))
rmse = sqrt(mean_squared_error(test.eurusd, predictions.eurusd))
print('Test RMSE: %.3f' % rmse)

"""Our 2 options here to perform roll forward validation -
- re-train the model each time as new data become available
- use the learned coecients and manually make predictions. 

1st option is computationaly expensive but a valid apporach as per as my knowledge is concern and I have opted for the same as below.
"""

# walk forward validation: the train set expanding each time step and the test set fixed at one time step ahead
# setting the formula for walk forward validation
X = original[15000:16000].values
n_train = 1
n_records = len(X)

for i in range(n_train, n_records):
    train, test = X[0:i], X[i:i+1]
    print('train=%d, test=%d' % (len(train), len(test)))

# re-train the model each time as new observations available
n_obs = int(15000) # number of initial observation
train = original[:n_obs]; test = original[n_obs:len(train)+1]
model = vecm.VECM(train.values, k_ar_diff = 6, coint_rank = 5, deterministic='co')
model_fit = model.fit()
print('Lag: %s' % model_fit.k_ar)
# predictions
pred_1 = model_fit.predict(len(test))
pred_1 = DataFrame(pred_1, columns = original.columns)
print('\033[4mEURUSD :: 1st prediction:\033[0m')
for i in range(len(pred_1)):
  print('predicted -> %f, actual -> %f' % (pred_1.eurusd[i], test.eurusd[i])); print()

tr1 = original[:len(train)+1]; te1 = original[len(tr1):len(tr1)+1]
model = vecm.VECM(tr1.values, k_ar_diff = 6, coint_rank = 5, deterministic='co')
model_fit = model.fit()
# predictions
pred_2 = model_fit.predict(len(te1))
pred_2 = DataFrame(pred_2, columns = original.columns)
print('\033[4mEURUSD :: 2nd prediction:\033[0m')
for i in range(len(pred_2)):
  print('predicted -> %f, actual -> %f' % (pred_2.eurusd[i], te1.eurusd[i])); print()

tr2 = original[:len(train)+2]; te2 = original[len(tr2):len(tr2)+1]
model = vecm.VECM(tr2.values, k_ar_diff = 6, coint_rank = 5, deterministic='co')
model_fit = model.fit()
# predictions
pred_3 = model_fit.predict(len(te2))
pred_3 = DataFrame(pred_3, columns = original.columns)
print('\033[4mEURUSD :: 3rd prediction:\033[0m')
for i in range(len(pred_3)):
  print('predicted -> %f, actual -> %f' % (pred_3.eurusd[i], te2.eurusd[i])); print()

tr3 = original[:len(train)+3]; te3 = original[len(tr3):len(tr3)+1]
model = vecm.VECM(tr3.values, k_ar_diff = 6, coint_rank = 5, deterministic='co')
model_fit = model.fit()
# predictions
pred_4 = model_fit.predict(len(te3))
pred_4 = DataFrame(pred_4, columns = original.columns)
print('\033[4mEURUSD :: 4th prediction:\033[0m')
for i in range(len(pred_4)):
  print('predicted -> %f, actual -> %f' % (pred_4.eurusd[i], te3.eurusd[i])); print()

tr4 = original[:len(train)+4]; te4 = original[len(tr4):len(tr4)+1]
model = vecm.VECM(tr4.values, k_ar_diff = 6, coint_rank = 5, deterministic='co')
model_fit = model.fit()
# predictions
pred_5 = model_fit.predict(len(te4))
pred_5 = DataFrame(pred_5, columns = original.columns)
print('\033[4mEURUSD :: 5th prediction:\033[0m')
for i in range(len(pred_5)):
  print('predicted -> %f, actual -> %f' % (pred_5.eurusd[i], te4.eurusd[i])); print()

tr5 = original[:len(train)+5]; te5 = original[len(tr5):len(tr5)+1]
model = vecm.VECM(tr5.values, k_ar_diff = 6, coint_rank = 5, deterministic='co')
model_fit = model.fit()
# predictions
pred_6 = model_fit.predict(len(te5))
pred_6 = DataFrame(pred_6, columns = original.columns)
print('\033[4mEURUSD :: 6th prediction:\033[0m')
for i in range(len(pred_6)):
  print('predicted -> %f, actual -> %f' % (pred_6.eurusd[i], te5.eurusd[i])); print()

tr6 = original[:len(train)+6]; te6 = original[len(tr6):len(tr6)+1]
model = vecm.VECM(tr6.values, k_ar_diff = 6, coint_rank = 5, deterministic='co')
model_fit = model.fit()
# predictions
pred_7 = model_fit.predict(len(te6))
pred_7 = DataFrame(pred_7, columns = original.columns)
print('\033[4mEURUSD :: 7th prediction:\033[0m')
for i in range(len(pred_7)):
  print('predicted -> %f, actual -> %f' % (pred_7.eurusd[i], te6.eurusd[i])); print()

tr7 = original[:len(train)+7]; te7 = original[len(tr7):len(tr7)+1]
model = vecm.VECM(tr7.values, k_ar_diff = 6, coint_rank = 5, deterministic='co')
model_fit = model.fit()
# predictions
pred_8 = model_fit.predict(len(te7))
pred_8 = DataFrame(pred_8, columns = original.columns)
print('\033[4mEURUSD :: 8th prediction:\033[0m')
for i in range(len(pred_8)):
  print('predicted -> %f, actual -> %f' % (pred_8.eurusd[i], te7.eurusd[i])); print()

tr8 = original[:len(train)+8]; te8 = original[len(tr8):len(tr8)+1]
model = vecm.VECM(tr8.values, k_ar_diff = 6, coint_rank = 5, deterministic='co')
model_fit = model.fit()
# predictions
pred_9 = model_fit.predict(len(te8))
pred_9 = DataFrame(pred_9, columns = original.columns)
print('\033[4mEURUSD :: 9th prediction:\033[0m')
for i in range(len(pred_9)):
  print('predicted -> %f, actual -> %f' % (pred_9.eurusd[i], te8.eurusd[i])); print()

tr9 = original[:len(train)+9]; te9 = original[len(tr9):len(tr9)+1]
model = vecm.VECM(tr9.values, k_ar_diff = 6, coint_rank = 5, deterministic='co')
model_fit = model.fit()
# predictions
pred_10 = model_fit.predict(len(te9))
pred_10 = DataFrame(pred_10, columns = original.columns)
print('\033[4mEURUSD :: 10th prediction:\033[0m')
for i in range(len(pred_10)):
  print('predicted -> %f, actual -> %f' % (pred_10.eurusd[i], te9.eurusd[i])); print()

tr10 = original[:len(train)+10]; te10 = original[len(tr10):len(tr10)+1]
model = vecm.VECM(tr10.values, k_ar_diff = 6, coint_rank = 5, deterministic='co')
model_fit = model.fit()
# predictions
pred_11 = model_fit.predict(len(te10))
pred_11 = DataFrame(predictions, columns = original.columns)
print('\033[4mEURUSD :: 11th prediction:\033[0m')
for i in range(len(pred_11)):
  print('predicted -> %f, actual -> %f' % (pred_11.eurusd[i], te10.eurusd[i])); print()

tr11 = original[:len(train)+11]; te11 = original[len(tr11):len(tr11)+1]
model = vecm.VECM(tr11.values, k_ar_diff = 6, coint_rank = 5, deterministic='co')
model_fit = model.fit()
# predictions
pred_12 = model_fit.predict(len(te11))
pred_12 = DataFrame(pred_12, columns = original.columns)
print('\033[4mEURUSD :: 12th prediction:\033[0m')
for i in range(len(pred_12)):
  print('predicted -> %f, actual -> %f' % (pred_12.eurusd[i], te11.eurusd[i])); print()

tr12 = original[:len(train)+12]; te12 = original[len(tr12):len(tr12)+1]
model = vecm.VECM(tr12.values, k_ar_diff = 6, coint_rank = 5, deterministic='co')
model_fit = model.fit()
# predictions
pred_13 = model_fit.predict(len(te12))
pred_13 = DataFrame(pred_13, columns = original.columns)
print('\033[4mEURUSD :: 13th prediction:\033[0m')
for i in range(len(pred_13)):
  print('predicted -> %f, actual -> %f' % (pred_13.eurusd[i], te12.eurusd[i])); print()

tr13 = original[:len(train)+13]; te13 = original[len(tr13):len(tr13)+1]
model = vecm.VECM(tr13.values, k_ar_diff = 6, coint_rank = 5, deterministic='co')
model_fit = model.fit()
# predictions
pred_14 = model_fit.predict(len(te13))
pred_14 = DataFrame(pred_14, columns = original.columns)
print('\033[4mEURUSD :: 14th prediction:\033[0m')
for i in range(len(pred_14)):
  print('predicted -> %f, actual -> %f' % (pred_14.eurusd[i], te13.eurusd[i])); print()

tr14 = original[:len(train)+14]; te14 = original[len(tr14):len(tr14)+1]
model = vecm.VECM(tr14.values, k_ar_diff = 6, coint_rank = 5, deterministic='co')
model_fit = model.fit()
# predictions
pred_15 = model_fit.predict(len(te14))
pred_15 = DataFrame(pred_15, columns = original.columns)
print('\033[4mEURUSD :: 15th prediction:\033[0m')
for i in range(len(pred_15)):
  print('predicted -> %f, actual -> %f' % (pred_15.eurusd[i], te14.eurusd[i])); print()

print('\033[4mEURCHF :: 1st prediction:\033[0m')
for i in range(len(pred_1)):
  print('predicted -> %f, actual -> %f' % (pred_1.eurchf[i], test.eurchf[i])); print()

print('\033[4mEURCHF :: 2nd prediction:\033[0m')
for i in range(len(pred_2)):
  print('predicted -> %f, actual -> %f' % (pred_2.eurchf[i], te1.eurchf[i])); print()

print('\033[4mEURCHF :: 3rd prediction:\033[0m')
for i in range(len(pred_3)):
  print('predicted -> %f, actual -> %f' % (pred_3.eurchf[i], te2.eurchf[i])); print()

print('\033[4mEURCHF :: 4th prediction:\033[0m')
for i in range(len(pred_4)):
  print('predicted -> %f, actual -> %f' % (pred_4.eurchf[i], te3.eurchf[i])); print()

print('\033[4mEURCHF :: 5th prediction:\033[0m')
for i in range(len(pred_5)):
  print('predicted -> %f, actual -> %f' % (pred_5.eurchf[i], te4.eurchf[i])); print()

print('\033[4mEURCHF :: 6th prediction:\033[0m')
for i in range(len(pred_6)):
  print('predicted -> %f, actual -> %f' % (pred_6.eurchf[i], te5.eurchf[i])); print()

print('\033[4mEURCHF :: 7th prediction:\033[0m')
for i in range(len(pred_7)):
  print('predicted -> %f, actual -> %f' % (pred_7.eurchf[i], te6.eurchf[i])); print()

print('\033[4mEURCHF :: 8th prediction:\033[0m')
for i in range(len(pred_8)):
  print('predicted -> %f, actual -> %f' % (pred_8.eurchf[i], te7.eurchf[i])); print()

print('\033[4mEURCHF :: 9th prediction:\033[0m')
for i in range(len(pred_8)):
  print('predicted -> %f, actual -> %f' % (pred_9.eurchf[i], te8.eurchf[i])); print()

print('\033[4mEURCHF :: 10th prediction:\033[0m')
for i in range(len(pred_10)):
  print('predicted -> %f, actual -> %f' % (pred_10.eurchf[i], te9.eurchf[i])); print()

print('\033[4mEURCHF :: 11th prediction:\033[0m')
for i in range(len(pred_11)):
  print('predicted -> %f, actual -> %f' % (pred_11.eurchf[i], te10.eurchf[i])); print()

print('\033[4mEURCHF :: 12th prediction:\033[0m')
for i in range(len(pred_12)):
  print('predicted -> %f, actual -> %f' % (pred_12.eurchf[i], te11.eurchf[i])); print()

print('\033[4mEURCHF :: 13th prediction:\033[0m')
for i in range(len(pred_13)):
  print('predicted -> %f, actual -> %f' % (pred_13.eurchf[i], te12.eurchf[i])); print()

print('\033[4mEURCHF :: 14th prediction:\033[0m')
for i in range(len(pred_14)):
  print('predicted -> %f, actual -> %f' % (pred_14.eurchf[i], te13.eurchf[i])); print()

print('\033[4mEURCHF :: 15th prediction:\033[0m')
for i in range(len(pred_15)):
  print('predicted -> %f, actual -> %f' % (pred_15.eurchf[i], te14.eurchf[i])); print()

"""# Clubbing all:"""

print('Necessary libraries & dependencies')
!pip install pyforest
from pyforest import *
import datetime, pickle, copy, warnings, math
from pandas import DataFrame, merge, concat
plt.style.use('dark_background')
from google.colab import files
!pip install arch
from arch.unitroot import DFGLS
pd.set_option('display.max_rows', 500)
pd.set_option('display.max_columns', 500)
pd.set_option('display.width', 150)
from sklearn.metrics import mean_absolute_error, mean_squared_error
from math import sqrt
from numpy import sqrt
from statsmodels.tsa.stattools import grangercausalitytests, adfuller
from statsmodels.stats.stattools import durbin_watson
from statsmodels.tsa.vector_ar import vecm
import statsmodels.stats.api as sms
from statsmodels.compat import lzip 

uploaded = files.upload()
print('view data...')
original = pd.read_csv("series_7_1.csv")
original = original.set_index('timestamp')
original = original.sort_index(ascending=True)

print('Granger Causality:')
max_lag = 6
test = 'ssr_chi2test'
def causation_matrix(data, variables, test='ssr_chi2test', verbose=False):    
  X = DataFrame(np.zeros((len(variables), len(variables))), columns=variables, index=variables)
  for c in X.columns:
    for r in X.index:
      test_result = grangercausalitytests(data[[r, c]], maxlag = max_lag, verbose = False)
      p_values = [round(test_result[i+1][0][test][1],4) for i in range(max_lag)]
      if verbose: print(f'Y = {r}, X = {c}, P Values = {p_values}')
      min_p_value = np.min(p_values)
      X.loc[r, c] = min_p_value
    X.columns = [var + '-x axis' for var in variables]
    X.index = [var + '-y axis' for var in variables]
    return X
print(causation_matrix(original, variables = original.columns)); print()

# re-train the model each time as new observations available
n_obs = int(15000) # number of initial observation
train_df = original[:n_obs]; test_df = original[n_obs:len(train_df)+1]
model = vecm.VECM(train_df.values, k_ar_diff = 6, coint_rank = 5, deterministic='co')
model_fit = model.fit()
print('Lag: %s' % model_fit.k_ar); print()

# Durbin-Watson
print('Durbin-Watson test:)')
out = durbin_watson(model_fit.resid)
for col, val in zip(original.columns, out):
    print((col), ':', round(val, 2))

# Residuals test
residuals = model_fit.resid
name = ['Jarque-Bera', 'Chi^2 two-tail prob.', 'Skew', 'Kurtosis']
test = sms.jarque_bera(residuals)
print(lzip(name, test)); print()
print('Correlation matrix:')
residuals = DataFrame(residuals, columns = original.columns)
print(residuals.corr()); print() # correlation matrix
print('Summary statistic:')
print(residuals.describe().transpose()) # statistic

# predictions
pred_1 = model_fit.predict(len(test_df))
pred_1 = DataFrame(pred_1, columns = original.columns)
print('\033[4mEURUSD :: 1st prediction:\033[0m')
for i in range(len(pred_1)):
  print('predicted -> %f, actual -> %f' % (pred_1.eurusd[i], test_df.eurusd[i])); print()

tr1 = original[:len(train_df)+1]; te1 = original[len(tr1):len(tr1)+1]
model = vecm.VECM(tr1.values, k_ar_diff = 6, coint_rank = 5, deterministic='co')
model_fit = model.fit()
# predictions
pred_2 = model_fit.predict(len(te1))
pred_2 = DataFrame(pred_2, columns = original.columns)
print('\033[4mEURUSD :: 2nd prediction:\033[0m')
for i in range(len(pred_2)):
  print('predicted -> %f, actual -> %f' % (pred_2.eurusd[i], te1.eurusd[i])); print()

tr2 = original[:len(train_df)+2]; te2 = original[len(tr2):len(tr2)+1]
model = vecm.VECM(tr2.values, k_ar_diff = 6, coint_rank = 5, deterministic='co')
model_fit = model.fit()
# predictions
pred_3 = model_fit.predict(len(te2))
pred_3 = DataFrame(pred_3, columns = original.columns)
print('\033[4mEURUSD :: 3rd prediction:\033[0m')
for i in range(len(pred_3)):
  print('predicted -> %f, actual -> %f' % (pred_3.eurusd[i], te2.eurusd[i])); print()

tr3 = original[:len(train_df)+3]; te3 = original[len(tr3):len(tr3)+1]
model = vecm.VECM(tr3.values, k_ar_diff = 6, coint_rank = 5, deterministic='co')
model_fit = model.fit()
# predictions
pred_4 = model_fit.predict(len(te3))
pred_4 = DataFrame(pred_4, columns = original.columns)
print('\033[4mEURUSD :: 4th prediction:\033[0m')
for i in range(len(pred_4)):
  print('predicted -> %f, actual -> %f' % (pred_4.eurusd[i], te3.eurusd[i])); print()

tr4 = original[:len(train_df)+4]; te4 = original[len(tr4):len(tr4)+1]
model = vecm.VECM(tr4.values, k_ar_diff = 6, coint_rank = 5, deterministic='co')
model_fit = model.fit()
# predictions
pred_5 = model_fit.predict(len(te4))
pred_5 = DataFrame(pred_5, columns = original.columns)
print('\033[4mEURUSD :: 5th prediction:\033[0m')
for i in range(len(pred_5)):
  print('predicted -> %f, actual -> %f' % (pred_5.eurusd[i], te4.eurusd[i])); print()

tr5 = original[:len(train_df)+5]; te5 = original[len(tr5):len(tr5)+1]
model = vecm.VECM(tr5.values, k_ar_diff = 6, coint_rank = 5, deterministic='co')
model_fit = model.fit()
# predictions
pred_6 = model_fit.predict(len(te5))
pred_6 = DataFrame(pred_6, columns = original.columns)
print('\033[4mEURUSD :: 6th prediction:\033[0m')
for i in range(len(pred_6)):
  print('predicted -> %f, actual -> %f' % (pred_6.eurusd[i], te5.eurusd[i])); print()

tr6 = original[:len(train_df)+6]; te6 = original[len(tr6):len(tr6)+1]
model = vecm.VECM(tr6.values, k_ar_diff = 6, coint_rank = 5, deterministic='co')
model_fit = model.fit()
# predictions
pred_7 = model_fit.predict(len(te6))
pred_7 = DataFrame(pred_7, columns = original.columns)
print('\033[4mEURUSD :: 7th prediction:\033[0m')
for i in range(len(pred_7)):
  print('predicted -> %f, actual -> %f' % (pred_7.eurusd[i], te6.eurusd[i])); print()

tr7 = original[:len(train_df)+7]; te7 = original[len(tr7):len(tr7)+1]
model = vecm.VECM(tr7.values, k_ar_diff = 6, coint_rank = 5, deterministic='co')
model_fit = model.fit()
# predictions
pred_8 = model_fit.predict(len(te7))
pred_8 = DataFrame(pred_8, columns = original.columns)
print('\033[4mEURUSD :: 8th prediction:\033[0m')
for i in range(len(pred_8)):
  print('predicted -> %f, actual -> %f' % (pred_8.eurusd[i], te7.eurusd[i])); print()

tr8 = original[:len(train_df)+8]; te8 = original[len(tr8):len(tr8)+1]
model = vecm.VECM(tr8.values, k_ar_diff = 6, coint_rank = 5, deterministic='co')
model_fit = model.fit()
# predictions
pred_9 = model_fit.predict(len(te8))
pred_9 = DataFrame(pred_9, columns = original.columns)
print('\033[4mEURUSD :: 9th prediction:\033[0m')
for i in range(len(pred_9)):
  print('predicted -> %f, actual -> %f' % (pred_9.eurusd[i], te8.eurusd[i])); print()

tr9 = original[:len(train_df)+9]; te9 = original[len(tr9):len(tr9)+1]
model = vecm.VECM(tr9.values, k_ar_diff = 6, coint_rank = 5, deterministic='co')
model_fit = model.fit()
# predictions
pred_10 = model_fit.predict(len(te9))
pred_10 = DataFrame(pred_10, columns = original.columns)
print('\033[4mEURUSD :: 10th prediction:\033[0m')
for i in range(len(pred_10)):
  print('predicted -> %f, actual -> %f' % (pred_10.eurusd[i], te9.eurusd[i])); print()

tr10 = original[:len(train_df)+10]; te10 = original[len(tr10):len(tr10)+1]
model = vecm.VECM(tr10.values, k_ar_diff = 6, coint_rank = 5, deterministic='co')
model_fit = model.fit()
# predictions
pred_11 = model_fit.predict(len(te10))
pred_11 = DataFrame(pred_11, columns = original.columns)
print('\033[4mEURUSD :: 11th prediction:\033[0m')
for i in range(len(pred_11)):
  print('predicted -> %f, actual -> %f' % (pred_11.eurusd[i], te10.eurusd[i])); print()

tr11 = original[:len(train_df)+11]; te11 = original[len(tr11):len(tr11)+1]
model = vecm.VECM(tr11.values, k_ar_diff = 6, coint_rank = 5, deterministic='co')
model_fit = model.fit()
# predictions
pred_12 = model_fit.predict(len(te11))
pred_12 = DataFrame(pred_12, columns = original.columns)
print('\033[4mEURUSD :: 12th prediction:\033[0m')
for i in range(len(pred_12)):
  print('predicted -> %f, actual -> %f' % (pred_12.eurusd[i], te11.eurusd[i])); print()

tr12 = original[:len(train_df)+12]; te12 = original[len(tr12):len(tr12)+1]
model = vecm.VECM(tr12.values, k_ar_diff = 6, coint_rank = 5, deterministic='co')
model_fit = model.fit()
# predictions
pred_13 = model_fit.predict(len(te12))
pred_13 = DataFrame(pred_13, columns = original.columns)
print('\033[4mEURUSD :: 13th prediction:\033[0m')
for i in range(len(pred_13)):
  print('predicted -> %f, actual -> %f' % (pred_13.eurusd[i], te12.eurusd[i])); print()

tr13 = original[:len(train_df)+13]; te13 = original[len(tr13):len(tr13)+1]
model = vecm.VECM(tr13.values, k_ar_diff = 6, coint_rank = 5, deterministic='co')
model_fit = model.fit()
# predictions
pred_14 = model_fit.predict(len(te13))
pred_14 = DataFrame(pred_14, columns = original.columns)
print('\033[4mEURUSD :: 14th prediction:\033[0m')
for i in range(len(pred_14)):
  print('predicted -> %f, actual -> %f' % (pred_14.eurusd[i], te13.eurusd[i])); print()

tr14 = original[:len(train_df)+14]; te14 = original[len(tr14):len(tr14)+1]
model = vecm.VECM(tr14.values, k_ar_diff = 6, coint_rank = 5, deterministic='co')
model_fit = model.fit()
# predictions
pred_15 = model_fit.predict(len(te14))
pred_15 = DataFrame(pred_15, columns = original.columns)
print('\033[4mEURUSD :: 15th prediction:\033[0m')
for i in range(len(pred_15)):
  print('predicted -> %f, actual -> %f' % (pred_15.eurusd[i], te14.eurusd[i])); print()
print("####################################################################")

print('\033[4mEURCHF :: 1st prediction:\033[0m')
for i in range(len(pred_1)):
  print('predicted -> %f, actual -> %f' % (pred_1.eurchf[i], test_df.eurchf[i])); print()

print('\033[4mEURCHF :: 2nd prediction:\033[0m')
for i in range(len(pred_2)):
  print('predicted -> %f, actual -> %f' % (pred_2.eurchf[i], te1.eurchf[i])); print()

print('\033[4mEURCHF :: 3rd prediction:\033[0m')
for i in range(len(pred_3)):
  print('predicted -> %f, actual -> %f' % (pred_3.eurchf[i], te2.eurchf[i])); print()

print('\033[4mEURCHF :: 4th prediction:\033[0m')
for i in range(len(pred_4)):
  print('predicted -> %f, actual -> %f' % (pred_4.eurchf[i], te3.eurchf[i])); print()

print('\033[4mEURCHF :: 5th prediction:\033[0m')
for i in range(len(pred_5)):
  print('predicted -> %f, actual -> %f' % (pred_5.eurchf[i], te4.eurchf[i])); print()

print('\033[4mEURCHF :: 6th prediction:\033[0m')
for i in range(len(pred_6)):
  print('predicted -> %f, actual -> %f' % (pred_6.eurchf[i], te5.eurchf[i])); print()

print('\033[4mEURCHF :: 7th prediction:\033[0m')
for i in range(len(pred_7)):
  print('predicted -> %f, actual -> %f' % (pred_7.eurchf[i], te6.eurchf[i])); print()

print('\033[4mEURCHF :: 8th prediction:\033[0m')
for i in range(len(pred_8)):
  print('predicted -> %f, actual -> %f' % (pred_8.eurchf[i], te7.eurchf[i])); print()

print('\033[4mEURCHF :: 9th prediction:\033[0m')
for i in range(len(pred_8)):
  print('predicted -> %f, actual -> %f' % (pred_9.eurchf[i], te8.eurchf[i])); print()

print('\033[4mEURCHF :: 10th prediction:\033[0m')
for i in range(len(pred_10)):
  print('predicted -> %f, actual -> %f' % (pred_10.eurchf[i], te9.eurchf[i])); print()

print('\033[4mEURCHF :: 11th prediction:\033[0m')
for i in range(len(pred_11)):
  print('predicted -> %f, actual -> %f' % (pred_11.eurchf[i], te10.eurchf[i])); print()

print('\033[4mEURCHF :: 12th prediction:\033[0m')
for i in range(len(pred_12)):
  print('predicted -> %f, actual -> %f' % (pred_12.eurchf[i], te11.eurchf[i])); print()

print('\033[4mEURCHF :: 13th prediction:\033[0m')
for i in range(len(pred_13)):
  print('predicted -> %f, actual -> %f' % (pred_13.eurchf[i], te12.eurchf[i])); print()

print('\033[4mEURCHF :: 14th prediction:\033[0m')
for i in range(len(pred_14)):
  print('predicted -> %f, actual -> %f' % (pred_14.eurchf[i], te13.eurchf[i])); print()

print('\033[4mEURCHF :: 15th prediction:\033[0m')
for i in range(len(pred_15)):
  print('predicted -> %f, actual -> %f' % (pred_15.eurchf[i], te14.eurchf[i])); print()